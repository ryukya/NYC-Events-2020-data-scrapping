{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NYC events scrapping data",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEInDuNatHfyVktTMqyuSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryukya/NYC-Events-2020-data-scrapping/blob/main/NYC_events_scrapping_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OvjivCtsSm"
      },
      "source": [
        "# Events scrapping for May and June 2020\n",
        "Source: https://www.nycgovparks.org/events/f2020-05-01/t2020-06-30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGldBWcXtVUf"
      },
      "source": [
        "Reference for scrapping:\n",
        "\n",
        "\n",
        "1.   https://kshivan848.medium.com/web-scraping-using-python-and-beautifulsoup-c71aaaae4ec3\n",
        "2.   https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
        "3. https://www.edureka.co/blog/web-scraping-with-python/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV6TLINSJph3",
        "outputId": "41ce0f20-32cd-4bb7-b20d-8509817ae7a6"
      },
      "source": [
        "!pip install requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYYxbyEuKuE6",
        "outputId": "fe3fb64c-4738-4010-cbd2-0333f82e841b"
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tnCmwbxKwrR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import bs4\n",
        "import lxml.etree as xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bff3psQuONFw"
      },
      "source": [
        "#Data from NYCGOVPARKS for 2020 05-06 (json)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG_VZqhieiHv"
      },
      "source": [
        "records = [] \n",
        "for i in range(48):      # Number of pages plus one \n",
        "    url = \"https://www.nycgovparks.org/events/f2020-05-01/t2020-06-30/p{}\".format(i)\n",
        "    web_page_text = requests.get(url).text\n",
        "    web_page = bs4.BeautifulSoup(web_page_text, \"lxml\")\n",
        "    event_obj = web_page.find_all(name=\"div\", attrs={\"itemtype\": \"http://schema.org/Event\"})\n",
        "    for result in event_obj:\n",
        "      title = result.find('a').text\n",
        "      date = result.find('a')['href'][8:19]\n",
        "      startDt = result.find(name=\"meta\", attrs={\"itemprop\": \"startDate\"}).get('content')\n",
        "      endDt = result.find(name=\"meta\", attrs={\"itemprop\": \"endDate\"}).get('content')\n",
        "      borough_loc = result.find(name=\"span\", attrs={\"itemprop\": \"addressLocality\"})\n",
        "      if borough_loc is not None:\n",
        "        borough_loc = borough_loc.text\n",
        "      event_loc = result.find(name=\"span\", attrs={\"itemprop\": \"name\"})\n",
        "      if event_loc is not None:\n",
        "        event_loc = event_loc.text\n",
        "      records.append((title, date, startDt, endDt, borough_loc, event_loc))\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5zUiC-Yid-y",
        "outputId": "562c0ac9-c844-47af-d8c8-b4dffce4e8d0"
      },
      "source": [
        "records [-3:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Virtual Yoga - Live!',\n",
              "  '2020/06/30/',\n",
              "  '2020-06-30T18:30:00-04:00',\n",
              "  '2020-06-30T19:30:00-04:00',\n",
              "  None,\n",
              "  'Virtual/Online Workshop'),\n",
              " ('Summer on the Hudson: Pilates Online',\n",
              "  '2020/06/30/',\n",
              "  '2020-06-30T18:30:00-04:00',\n",
              "  '2020-06-30T19:30:00-04:00',\n",
              "  None,\n",
              "  'Virtual/Online Workshop')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2JbGmnDg6x-"
      },
      "source": [
        "records [-3:-1]\n",
        "#import to csv\n",
        "import csv\n",
        "file = open('park2020.csv', 'w+', newline ='') \n",
        "with file:     \n",
        "    write = csv.writer(file) \n",
        "    write.writerows(records) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vScOVhg424XY"
      },
      "source": [
        "Data from NYCgov. use this  https://www.convertcsv.com/json-to-csv.htm \n",
        "(convert json to csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oatro_00hoGC"
      },
      "source": [
        "URL2 = \"https://www1.nyc.gov/calendar/api/json/search.htm?startDate=05/01/2020%2012:00%20AM&endDate=06/30/2020%2011:59%20PM&sort=DATE&pageNumber=1\"\n",
        "\n",
        "#web_page_text2 = requests.get(URL2).text\n",
        "#web_page2 = bs4.BeautifulSoup(web_page_text2, \"lxml\")\n",
        "#print(web_page2)\n",
        "#title = web_page2.find('body')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MixGRUrpcfKT"
      },
      "source": [
        "### Combine the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0y72JzScXoL"
      },
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "\n",
        "path = \"/home/data/\"\n",
        "\n",
        "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "\n",
        "all_df = []\n",
        "for f in all_files:\n",
        "    df = pd.read_csv(f, sep=',')\n",
        "    df['file'] = f.split('/')[-1]\n",
        "    all_df.append(df)\n",
        "    \n",
        "merged_df = pd.concat(all_df, ignore_index=True, sort=True)\n",
        "merged_df.to_csv( \"merged.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqjQB8vCdjYa",
        "outputId": "a0242d0a-7d25-43eb-8dd6-e2cd26dad2d4"
      },
      "source": [
        "print(merged_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               address  ... zip\n",
            "0                                              All NYC  ... NaN\n",
            "1                               All NYC Public Schools  ... NaN\n",
            "2     WEST   97 STREET between COLUMBUS AVENUE and ...  ... NaN\n",
            "3     EAST  149 STREET between MORRIS AVENUE and PA...  ... NaN\n",
            "4     WEST HOUSTON STREET between THOMPSON STREET a...  ... NaN\n",
            "..                                                 ...  ...  ..\n",
            "315                                            All NYC  ... NaN\n",
            "316                             All NYC Public Schools  ... NaN\n",
            "317                                            All NYC  ... NaN\n",
            "318                             All NYC Public Schools  ... NaN\n",
            "319                                            All NYC  ... NaN\n",
            "\n",
            "[320 rows x 34 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXdOcM_PLZCq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}